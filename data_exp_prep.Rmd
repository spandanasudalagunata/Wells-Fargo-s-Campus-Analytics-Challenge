---
title: "Data Exploration & Preparation"
author:
- Prof. Murali Shanker (@mshanker1) - Advisor
- Nick (@odintech3)
- Spandana (@spandanasudalagunta)
- Tina (@davinia1991)
output:
  html_document:
    df_print: paged
---

```{r warning = F}
library("dplyr")
library("magrittr")
library("readxl")
library("ggplot2")
```

```{r echo = F}
# A list of all the sources and activities
sources <- c(
  "solar_powered_water_heater",
  "gas_water_heater",
  "electric_water_heater_peak_hour",
  "electric_water_heater_off_peak",
  "gas",
  "natural_gas",
  "hybrid",
  "electric_peak_hours",
  "electric_off_peak_hours",
  "jetfuel"
)

activities <- c(
  "Household heating => 70F","Household heating < 70F",
  "Use of heat pump","Use of air conditioner",
  "shower - short","shower - long (> 3 min)",
  "bath","wash-up",
  "use of dishwasher","use of clothes washer",
  "use of clothes dryer", "use of cooking range",
  "use of  oven","use of self-clean feature of electric oven",
  "Small kitchen appliance in the home", "TV/computer use",
  "air travel - large plane", "air travel - small  plane (<50 seats)",
  "car trips- self only", "car trips - driver and self",
  "car trips - 2+ people with multiple end points", "trips using public ground transportation",
  "bags of garbage disposed", "bags of recycling deposited (negative CF)",
  "bags of compost deposited (negative CF)","hazardous or electric items disposed",
  "large items disposed"
)
```

#Wells Fargo's Campus Analytics Challenge: Live Green and Live Happy

One of Wells Fargoâ€™s priorities is to promote environmental sustainability, which includes accelerating the transition to a low-carbon economy. Taking individual actions can encourage collective responsibility to help achieve this. Using machine learning, create a data product to help individuals optimize the balance between their carbon footprint and quality of life. The data gives a peek into the lives of 1,000 individuals who rated several everyday activities (taking a long shower, driving a car, etc.) on a scale of 1-100 based on how important those activities are to their daily lives.

#Objective
The goal of this project is to create a machine learning algorithm that minimizes carbon footprint for each customer while maintaining their total quality of life.



Loading the data into R where sheet1 has the information regrading the individuals and their consumption and sheet2 has information about the carbon footprint for each activity.
```{r}
sheet1 <- read_excel(
  "data/dataset.xlsx",
  sheet = "Individuals",
  range = "A1:P27055"
)

sheet2 <- read_excel(
  "data/dataset.xlsx",
  sheet = "Carbon Footprint",
  range = "A2:N29"
)
```

Below we have a summary of sheet 1 from the excel dataset (excluding sources) to get the summary of the data we are dealing with.

```{r}
sheet1 %>%
  select(-sources) %>%
  summary(sheet1)
```
 We are trying to look at the data for individual 1  

```{r}
sheet1 %>%
  select(-sources) %>%
  filter(Indnum == 1) %>% 
  head()
```


# Data Cleaning

After reviewing the data we have noticed a lot of missing values. we are assuming that the `NA` values are present in the data because the individual didnot have any consumption for the activity and did not give any rating for the quality of life. we are replacing  all `NA` values in sheet 1 with 0.

```{r}
sheet1[is.na(sheet1)] <- 0 

sheet1 %>% 
  head()
```
Replacing all the all `NA` values in sheet2 with 0
```{r}
sheet2[is.na(sheet2)] <- 0 

sheet2 %>%
  head()
```
Converting the negative values in consumption to positive values.
```{r}
sheet1 <- sheet1 %>%
  mutate_at(.vars = vars(Consumption), .funs = funs(abs))

summary(sheet1)
```

```{r echo = F}
write.csv(sheet2, "./data/dataset_source_cf.csv")
```

```{r echo = F}
sheet1 %>%
  select(Indnum, Activity, sources) %>%
  write.csv("./data/dataset_without_source_cf.csv")
```


Below we are filling the carbon footprint for each activity, where ever the source has 1 the corresponding carbonfootprint value is filled.

```{r}
for (activity in activities) {
  cf_activity <- as.vector(unlist(sheet2[sheet2$Activity == activity, sources]))
  activity_sources <- sheet1[sheet1$Activity == activity, sources]
  result <- data.frame(mapply(`*`, activity_sources, cf_activity, SIMPLIFY = F)) 
  
  sheet1[sheet1$Activity == activity, sources] <- result
}
```

Below is a graph showing the sum of consumptions for each activity in their respective units.

```{r}
sheet1 %>%
  select(Activity, Consumption) %>%
  group_by(Activity) %>%
  summarise(sum_consumption = sum(Consumption)) %>%
  arrange(desc(sum_consumption)) %>%
  ggplot(aes(x = Activity, y = sum_consumption, fill = sum_consumption)) +
  geom_bar(stat = 'identity') +
  coord_flip() +
  theme_minimal() +
  guides(fill = F)
  
```

Below table shows the maximum and minimum units of consumption for each activity.

```{r}
sheet1 %>% 
  select(Activity, Consumption) %>%
  group_by(Activity) %>%
  summarise(max_consumption = max(Consumption), min_consumption = min(Consumption))
```

# Data Preparation

In the data preparation stage we have created two new variables TCF = Total carbon footprint for each individual per activity and TrQL = product of consumption and quality of life for each individual per activity. 

```{r}
sheet1 <- sheet1 %>%
  mutate(
    TCF = rowSums(.[,sources]),
    TrQL = Consumption * Quality_of_Life_Importance__1_10)

head(sheet1)
```


```{r echo = F}
write.csv(sheet1, "./data/dataset.csv")
```
